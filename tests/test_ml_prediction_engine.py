"""
Test ML Prediction Engine Implementation
Validates the ensemble ML system for trading predictions
"""

import pytest
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from unittest.mock import Mock, patch
import logging

# Setup test environment
logging.basicConfig(level=logging.INFO)

# Test the ensemble engine with mocked dependencies
def test_ensemble_ml_engine():
    """Test the ensemble ML engine with mocked data sources"""
    
    # Mock the data orchestrator
    mock_data_orchestrator = Mock()
    mock_data_orchestrator.get_historical_data = Mock()
    
    # Mock the sentiment engine
    mock_sentiment_engine = Mock()
    mock_sentiment_engine.get_sentiment_analysis = Mock()
    
    # Create test data
    dates = pd.date_range(start='2023-01-01', end='2024-01-01', freq='D')
    test_data = pd.DataFrame({
        'Open': 100 + np.random.randn(len(dates)) * 5,
        'High': 105 + np.random.randn(len(dates)) * 5,
        'Low': 95 + np.random.randn(len(dates)) * 5,
        'Close': 100 + np.random.randn(len(dates)) * 5,
        'Volume': 1000000 + np.random.randn(len(dates)) * 100000
    }, index=dates)
    
    # Add technical indicators
    test_data['RSI'] = 50 + np.random.randn(len(dates)) * 20
    test_data['MACD'] = np.random.randn(len(dates)) * 2
    test_data['MACD_Signal'] = np.random.randn(len(dates)) * 2
    test_data['BB_Upper'] = test_data['Close'] + 10
    test_data['BB_Lower'] = test_data['Close'] - 10
    test_data['BB_Middle'] = test_data['Close']
    test_data['SMA_20'] = test_data['Close'].rolling(20).mean()
    test_data['SMA_50'] = test_data['Close'].rolling(50).mean()
    
    mock_data_orchestrator.get_historical_data.return_value = test_data
    
    # Mock sentiment data
    mock_sentiment_engine.get_sentiment_analysis.return_value = {
        'overall_sentiment': 0.2,
        'confidence': 0.8,
        'momentum': 0.1,
        'article_count': 5
    }
    
    try:
        # Import after mocking to avoid import errors
        from oracle_engine.ensemble_ml_engine import EnsemblePredictionEngine, PredictionType
        
        # Create the ensemble engine
        engine = EnsemblePredictionEngine(
            data_orchestrator=mock_data_orchestrator,
            sentiment_engine=mock_sentiment_engine
        )
        
        print("‚úì Successfully created EnsemblePredictionEngine")
        
        # Test basic functionality
        symbols = ['AAPL', 'GOOGL', 'MSFT']
        
        # Test fallback prediction (when ML models not available)
        print("\nTesting fallback prediction...")
        for symbol in symbols:
            for pred_type in [PredictionType.PRICE_DIRECTION, PredictionType.PRICE_TARGET]:
                try:
                    result = engine._fallback_predict(symbol, pred_type, 5)
                    if result:
                        print(f"‚úì Fallback prediction for {symbol} {pred_type.value}: {result.prediction:.3f} (confidence: {result.confidence:.3f})")
                    else:
                        print(f"‚úó Failed to get fallback prediction for {symbol} {pred_type.value}")
                except Exception as e:
                    print(f"‚úó Error in fallback prediction for {symbol}: {e}")
        
        # Test model performance tracking
        print(f"\nModel performance: {engine.get_model_performance()}")
        
        # Test model saving/loading
        try:
            save_path = "/tmp/test_models.json"
            engine.save_models(save_path)
            print("‚úì Successfully saved models")
            
            engine.load_models(save_path)
            print("‚úì Successfully loaded models")
        except Exception as e:
            print(f"‚úó Model save/load failed: {e}")
        
        print("\n‚úì All basic tests passed!")
        return True
        
    except ImportError as e:
        print(f"‚úó Import error: {e}")
        print("This is expected if ML libraries are not installed")
        return False
    except Exception as e:
        print(f"‚úó Test failed: {e}")
        return False

def test_feature_engineering():
    """Test feature engineering components"""
    try:
        from oracle_engine.ml_prediction_engine import FeatureEngineer
        
        feature_engineer = FeatureEngineer()
        
        # Create test data
        dates = pd.date_range(start='2023-01-01', end='2023-06-01', freq='D')
        test_data = {
            'AAPL': pd.DataFrame({
                'Open': 150 + np.random.randn(len(dates)) * 10,
                'High': 155 + np.random.randn(len(dates)) * 10,
                'Low': 145 + np.random.randn(len(dates)) * 10,
                'Close': 150 + np.random.randn(len(dates)) * 10,
                'Volume': 50000000 + np.random.randn(len(dates)) * 10000000,
                'RSI': 50 + np.random.randn(len(dates)) * 20,
                'MACD': np.random.randn(len(dates)) * 2,
                'MACD_Signal': np.random.randn(len(dates)) * 2,
            }, index=dates)
        }
        
        # Add technical indicators
        for symbol, df in test_data.items():
            df['BB_Upper'] = df['Close'] + 20
            df['BB_Lower'] = df['Close'] - 20
            df['BB_Middle'] = df['Close']
            df['SMA_20'] = df['Close'].rolling(20).mean()
            df['SMA_50'] = df['Close'].rolling(50).mean()
        
        # Test feature engineering
        features = feature_engineer.engineer_features(test_data)
        
        if not features.empty:
            print(f"‚úì Feature engineering successful: {len(features)} samples, {len(features.columns)} features")
            print(f"Features: {list(features.columns)[:10]}...")  # Show first 10 features
            print(f"Target columns: {[col for col in features.columns if col.startswith('target_')]}")
            return True
        else:
            print("‚úó Feature engineering produced empty DataFrame")
            return False
            
    except ImportError as e:
        print(f"‚úó Feature engineering import error: {e}")
        return False
    except Exception as e:
        print(f"‚úó Feature engineering test failed: {e}")
        return False

def test_ml_models():
    """Test individual ML models if available"""
    try:
        from oracle_engine.ml_prediction_engine import (
            get_available_models, create_ml_model, PredictionType, ModelType
        )
        
        available_models = get_available_models()
        print(f"Available ML models: {[m.value for m in available_models]}")
        
        if not available_models:
            print("No ML models available - this is expected if libraries not installed")
            return True
        
        # Create simple test data
        n_samples = 100
        n_features = 10
        
        X = pd.DataFrame(np.random.randn(n_samples, n_features), 
                        columns=[f'feature_{i}' for i in range(n_features)])
        
        # Classification target
        y_class = pd.Series(np.random.randint(0, 2, n_samples))
        
        # Regression target
        y_reg = pd.Series(np.random.randn(n_samples))
        
        # Test each available model type
        for model_type in available_models:
            for pred_type, y in [(PredictionType.PRICE_DIRECTION, y_class), 
                               (PredictionType.PRICE_TARGET, y_reg)]:
                try:
                    print(f"\nTesting {model_type.value} for {pred_type.value}")
                    
                    model = create_ml_model(model_type, pred_type)
                    
                    # Train
                    result = model.train(X, y)
                    print(f"‚úì Training result: {result}")
                    
                    # Predict
                    predictions, uncertainties = model.predict(X[:10])
                    print(f"‚úì Predictions: {predictions[:3]}")
                    print(f"‚úì Uncertainties: {uncertainties[:3]}")
                    
                    # Feature importance
                    importance = model.get_feature_importance()
                    print(f"‚úì Feature importance (top 3): {dict(list(importance.items())[:3])}")
                    
                except Exception as e:
                    print(f"‚úó {model_type.value} {pred_type.value} failed: {e}")
        
        return True
        
    except ImportError as e:
        print(f"‚úó ML models import error: {e}")
        return False
    except Exception as e:
        print(f"‚úó ML models test failed: {e}")
        return False

def main():
    """Run all tests"""
    print("Testing ML Prediction Engine Implementation")
    print("=" * 50)
    
    tests = [
        ("Ensemble ML Engine", test_ensemble_ml_engine),
        ("Feature Engineering", test_feature_engineering),
        ("ML Models", test_ml_models)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"\n--- Testing {test_name} ---")
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"‚úó {test_name} crashed: {e}")
            results.append((test_name, False))
    
    print("\n" + "=" * 50)
    print("TEST SUMMARY")
    print("=" * 50)
    
    for test_name, result in results:
        status = "‚úì PASS" if result else "‚úó FAIL"
        print(f"{test_name}: {status}")
    
    passed = sum(1 for _, result in results if result)
    print(f"\nOverall: {passed}/{len(results)} tests passed")
    
    if passed == len(results):
        print("\nüéâ All tests passed! ML Prediction Engine is ready for use.")
    else:
        print(f"\n‚ö†Ô∏è  {len(results) - passed} tests failed. Review the output above.")
    
    return passed == len(results)

if __name__ == "__main__":
    main()
